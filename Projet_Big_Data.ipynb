{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamel-amir/Projet_Big_Data/blob/main/Projet_Big_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projet Big Data : Apache Spark\n",
        "\n",
        "Réalisé par:\n",
        "\n",
        "* Amir  Hamel\n",
        "* Noor Khalal\n",
        "* Zahra Alliche"
      ],
      "metadata": {
        "id": "v2SIGKnLvWwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objectifs du TP\n",
        "Ce TP consiste à regrouper des documents textuels tels que les documents qui\n",
        "partagent le même thème se retrouvent dans le même groupe, et les documents qui\n",
        "portent sur des sujets très différents se trouvent dans des groupes différents."
      ],
      "metadata": {
        "id": "6iydR02cvmxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Mise en place de l'environnement de travail "
      ],
      "metadata": {
        "id": "hKIQ49q-vusK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Installation de Spark"
      ],
      "metadata": {
        "id": "4TLXcnVJv7L7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalation de la bibliotheque Java**"
      ],
      "metadata": {
        "id": "o7EwvSUfUMPs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "80GmyDXDMDkT"
      },
      "outputs": [],
      "source": [
        "! apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalation de Spark**"
      ],
      "metadata": {
        "id": "6LPzD234US-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -q https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n"
      ],
      "metadata": {
        "id": "Y1rF4IunvkGy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! tar xf spark-3.3.2-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "RbbI0dlqvyJs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Instalation de PySpark**"
      ],
      "metadata": {
        "id": "gwBBWDFiUZ9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# instalation de pyspark\n",
        "! pip install -q findspark\n",
        "! pip install pyspark"
      ],
      "metadata": {
        "id": "lFiWQgJdP_Re",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76282302-ef15-4635-80fc-448e56bd73de"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=fbdbd7a5ca36e8e3c4dcf90ec24899e8213c85876e20121971038507fbcae43a\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/59/a0/a1a0624b5e865fd389919c1a10f53aec9b12195d6747710baf\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3/4 Définir la vatiable d'environnement et créer l'objet SparkContext "
      ],
      "metadata": {
        "id": "v4UfhgnywKcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# definir deux variables d'environement\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"  # l'endroit de java\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\" # l'endroit de spark\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.5 pyspark-shell' \n",
        "\n",
        "import findspark\n",
        "findspark.init(\"spark-3.3.2-bin-hadoop3\")\n",
        "\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "# lancement du spark en local (en une seule machine qui est la machine virtuelle de colab dans ce cas) avec 4 processus (workers node)\n",
        "configuration = SparkConf().setAppName(\"name\").setMaster(\"local[4]\").set('spark.jars.packages', 'org.apache.spark:spark-avro_2.11:2.4.5')\n",
        "# name: c'est le nom qu'on donne a notre app (code)\n",
        "sc = SparkContext(conf=configuration) # l'objet "
      ],
      "metadata": {
        "id": "XqJL73UxQb6q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc"
      ],
      "metadata": {
        "id": "sLJc20MwVnsF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "38cec736-b971-43be-bb95-8261d99a39fe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[4] appName=name>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://50c33fcd0949:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.3.2</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[4]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>name</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Création de l'objet sparkSession**"
      ],
      "metadata": {
        "id": "Ym1IV3Y7VJaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# L'objet sparkSession créé pour utiliser l'API Spark SQL\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.config(conf=configuration).getOrCreate()"
      ],
      "metadata": {
        "id": "8CXmh37JVuoQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Données"
      ],
      "metadata": {
        "id": "MThv3ncHwciX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Téléchargement des données"
      ],
      "metadata": {
        "id": "HxJ4NfIDT6Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Téléchargement du dossier des documents\n",
        "! wget -q http://qwone.com/~jason/20Newsgroups/20news-19997.tar.gz"
      ],
      "metadata": {
        "id": "RwjFOBQ9WEIF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Decompression des données"
      ],
      "metadata": {
        "id": "lqfcBArSwr17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# décompresser le dossier \n",
        "! tar xf /content/20news-19997.tar.gz"
      ],
      "metadata": {
        "id": "XMNChhuTWPvX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Chargement des données dans deux variables de type RDD\n",
        "\n"
      ],
      "metadata": {
        "id": "6UGGCxnFUDb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd1 = sc.wholeTextFiles(\"/content/20_newsgroups/alt.atheism\")\n",
        "rdd2 = sc.wholeTextFiles(\"/content/20_newsgroups/rec.sport.baseball\")"
      ],
      "metadata": {
        "id": "IqUNkQFbdAOG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=rdd2.take(2)"
      ],
      "metadata": {
        "id": "_4_S17Z_dc0u"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.4 Séparation de l’entête"
      ],
      "metadata": {
        "id": "c1PJy4DoV3oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separateur(x):\n",
        "  l=x[1].split(\"\\n\\n\")\n",
        "  return (x[0],l)\n",
        "\n",
        "#separateur(x[1])\n",
        "\n",
        "rdd1=rdd1.map(separateur)\n",
        "rdd2=rdd2.map(separateur)"
      ],
      "metadata": {
        "id": "kdS3yOh9d-wY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tester le premier élément\n",
        "test=rdd1.take(1)\n",
        "test"
      ],
      "metadata": {
        "id": "8H3eWV5MkKB9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ad9963-68ec-4a43-ed76-8eb818a9869d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('file:/content/20_newsgroups/alt.atheism/53791',\n",
              "  ['Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53791 talk.religion.misc:84109 talk.origins:41079\\nNewsgroups: alt.atheism,talk.religion.misc,talk.origins\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!bb3.andrew.cmu.edu!news.sei.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!zaphod.mps.ohio-state.edu!swrinde!cs.utexas.edu!utnut!torn!nott!cunews!rjg\\nFrom: rjg@doe.carleton.ca (Richard Griffith)\\nSubject: Re: Burden of Proof\\nMessage-ID: <rjg.735427215@wesley>\\nSender: news@cunews.carleton.ca (News Administrator)\\nOrganization: Dept. of Electronics, Carleton University\\nReferences: <C5t5sF.8oz@mentor.cc.purdue.edu> <1r4b59$7hg@aurora.engr.LaTech.edu>\\nDate: Wed, 21 Apr 1993 21:20:15 GMT\\nLines: 23',\n",
              "   'In <1r4b59$7hg@aurora.engr.LaTech.edu> ray@engr.LaTech.edu (Bill Ray) writes:',\n",
              "   '>If I make a statement, \"That God exists, loves me, etc.\" but in no way\\n>insist that you believe it, does that place a burden of proof upon me.\\n>If you insist that God doesn\\'t exist, does that place a burden of proof \\n>upon you?  I give no proofs, I only give testimony to my beliefs.  I will\\n>respond to proofs that you attempt to disprove my beliefs.',\n",
              "   'What is your reaction to people who claim they were abducted by space aliens?',\n",
              "   'Some of these people say, \"I was abducted, experimented on, etc.\"\\nIf we insist that these aliens don\\'t exist is the burden of proof placed on\\nus. These people can give no hard facts but can give a lot of testimony to\\nback up their beliefs.',\n",
              "   'Replace <space aliens> with <elvis>, <big foot>, <blue unicorns>, \\nand we have a larger percentage of the population than I like to think\\nabout.',\n",
              "   'Sometimes I wonder if reality really is a different experience for everone.',\n",
              "   ''])]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On voit ici qu'un document est représenté sous la forme d'un tuple `(Path, List)`,\n",
        "\n",
        " ou `List = [entête, contenu du document ]`"
      ],
      "metadata": {
        "id": "UQ4YbyySzNDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.5 Extraction des champs de l’entête"
      ],
      "metadata": {
        "id": "tgkstGvWxDyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#fonction d'ectraction des éléments de l’entête\n",
        "#prend en prametre l’entête d'un document\n",
        "#retourne un dictionnaire (Intitulé_Champs, Contenu_Champs)\n",
        "\n",
        "def extraction_informations_entete(entete):\n",
        "  #chaque ligne représente un nouveau champs\n",
        "  l=entete.split(\"\\n\")\n",
        "  d=dict()\n",
        "\n",
        "  for x in l:\n",
        "    #l'intitulé du champs est séparé de son contenu par ':'\n",
        "    z=x.split(\":\")\n",
        "    #quelques lignes ne contiennent pas de ':'\n",
        "    if len(z)==2:\n",
        "       d[z[0]]=z[1]\n",
        "\n",
        "  return d"
      ],
      "metadata": {
        "id": "s_87u2qsn3Tc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Premier example d'extraction"
      ],
      "metadata": {
        "id": "zHcZknYryqRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extraire des informations du premier document du rdd1 (alt.atheism)\n",
        "\n",
        "# par l'action first\n",
        "doc1=rdd1.first()\n",
        "entete=doc1[1][0]\n",
        "\n",
        "# Dictionnaire des informations de l'entete\n",
        "dict1_info=extraction_informations_entete(entete)\n",
        "dict1_info"
      ],
      "metadata": {
        "id": "jb3WmurZq4PR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c48518-aaa5-4894-a144-8d38b0c2ad29"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Newsgroups': ' alt.atheism,talk.religion.misc,talk.origins',\n",
              " 'Path': ' cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!bb3.andrew.cmu.edu!news.sei.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!zaphod.mps.ohio-state.edu!swrinde!cs.utexas.edu!utnut!torn!nott!cunews!rjg',\n",
              " 'From': ' rjg@doe.carleton.ca (Richard Griffith)',\n",
              " 'Message-ID': ' <rjg.735427215@wesley>',\n",
              " 'Sender': ' news@cunews.carleton.ca (News Administrator)',\n",
              " 'Organization': ' Dept. of Electronics, Carleton University',\n",
              " 'References': ' <C5t5sF.8oz@mentor.cc.purdue.edu> <1r4b59$7hg@aurora.engr.LaTech.edu>',\n",
              " 'Lines': ' 23'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# selectionner Organization et Newsgroups\n",
        "print(dict1_info['Newsgroups'])\n",
        "print(dict1_info['Organization'])"
      ],
      "metadata": {
        "id": "1fy0wE-qtfTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5241cbe5-ef4d-436e-a57f-384833572ef1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " alt.atheism,talk.religion.misc,talk.origins\n",
            " Dept. of Electronics, Carleton University\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Deuxieme example d'extraction"
      ],
      "metadata": {
        "id": "ixAxKaLe0IRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# par l'action take\n",
        "doc2=rdd2.take(2)\n",
        "entete2=doc2[1][1][0]\n",
        "# Dictionnaire des informations de l'entete\n",
        "dict2_info=extraction_informations_entete(entete2)\n",
        "dict2_info"
      ],
      "metadata": {
        "id": "PRntxXwVsQYu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7e5ffcc-5c18-447c-b251-976d5504b2fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Newsgroups': ' rec.sport.baseball',\n",
              " 'Path': ' cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!usenet.ins.cwru.edu!wsu-cs!vela.acs.oakland.edu!cs.uiuc.edu!cs.uiuc.edu!steph',\n",
              " 'From': ' steph@cs.uiuc.edu (Dale Stephenson)',\n",
              " 'Subject': ' Defensive Averages 1988-1992, Third Base',\n",
              " 'Message-ID': ' <C5JJrJ.EM3@cs.uiuc.edu>',\n",
              " 'Summary': ' career defensive averages at third',\n",
              " 'Organization': ' University of Illinois, Dept. of Comp. Sci., Urbana, IL',\n",
              " 'Lines': ' 68'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# selectionner Organization et Newsgroups\n",
        "print(dict2_info['Newsgroups'])\n",
        "print(dict2_info['Organization'])"
      ],
      "metadata": {
        "id": "5vGSXmr8tM09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46e3e979-6d5a-4a64-d3f8-513ed9fc8f0a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " rec.sport.baseball\n",
            " University of Illinois, Dept. of Comp. Sci., Urbana, IL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici, nous allons créer une nouvelle fonction de séparation de document qui va créer un élément de RDD de la forme \n",
        "`(Path, [Dictionnaire de l'entete , le contenu du document])`\n",
        "\n",
        "Ceci rendra la transformation des élément en type pyspark.sql.Row plus facile durant le choix des colonnes car certains champs de l,entete n'e=éxistent pas dans tous les documents, le test d'éxistance sera plus facile grace au dictionnaire."
      ],
      "metadata": {
        "id": "ofHCO1re0PlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cette fonction prend en entrée un élement du rdd (doc)\n",
        "# et retourne un tuple contenant ( path, [dictionnaire de l'entete , le contenu du document])\n",
        "def structuration_document(doc):\n",
        "  if  doc is not None:\n",
        "    l= doc[1][0].split(\"\\n\")\n",
        "    d=dict()\n",
        "    if len(l)!=0:\n",
        "      for x in l:\n",
        "        z=x.split(\":\",1)\n",
        "        if len(z)==2:\n",
        "          d[z[0]]=z[1]\n",
        "        if len(z)<2:\n",
        "           pass\n",
        "        \n",
        "\n",
        "      return (doc[0],[d,doc[1][1]])"
      ],
      "metadata": {
        "id": "iP2HOZSXCjuS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_rdd1=rdd1.map(structuration_document)\n"
      ],
      "metadata": {
        "id": "GDfaOLzGCSwg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# affichage du resultat de new_rdd1\n",
        "new_rdd1.take(2)"
      ],
      "metadata": {
        "id": "6E0EShNhDahC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e02f6de-ca42-47a1-e438-45d8a35653cd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('file:/content/20_newsgroups/alt.atheism/53791',\n",
              "  [{'Xref': ' cantaloupe.srv.cs.cmu.edu alt.atheism:53791 talk.religion.misc:84109 talk.origins:41079',\n",
              "    'Newsgroups': ' alt.atheism,talk.religion.misc,talk.origins',\n",
              "    'Path': ' cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!bb3.andrew.cmu.edu!news.sei.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!zaphod.mps.ohio-state.edu!swrinde!cs.utexas.edu!utnut!torn!nott!cunews!rjg',\n",
              "    'From': ' rjg@doe.carleton.ca (Richard Griffith)',\n",
              "    'Subject': ' Re: Burden of Proof',\n",
              "    'Message-ID': ' <rjg.735427215@wesley>',\n",
              "    'Sender': ' news@cunews.carleton.ca (News Administrator)',\n",
              "    'Organization': ' Dept. of Electronics, Carleton University',\n",
              "    'References': ' <C5t5sF.8oz@mentor.cc.purdue.edu> <1r4b59$7hg@aurora.engr.LaTech.edu>',\n",
              "    'Date': ' Wed, 21 Apr 1993 21:20:15 GMT',\n",
              "    'Lines': ' 23'},\n",
              "   'In <1r4b59$7hg@aurora.engr.LaTech.edu> ray@engr.LaTech.edu (Bill Ray) writes:']),\n",
              " ('file:/content/20_newsgroups/alt.atheism/54220',\n",
              "  [{'Path': ' cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!usenet.ins.cwru.edu!po.CWRU.edu!kmr4',\n",
              "    'From': ' kmr4@po.CWRU.edu (Keith M. Ryan)',\n",
              "    'Newsgroups': ' alt.atheism',\n",
              "    'Subject': ' Re: free moral agency',\n",
              "    'Date': ' Thu, 22 Apr 1993 23:48:54 GMT',\n",
              "    'Organization': ' Case Western Reserve University',\n",
              "    'Lines': ' 29',\n",
              "    'Message-ID': ' <kmr4.1678.735522534@po.CWRU.edu>',\n",
              "    'References': ' <1993Apr19.161248.23708@welchgate.welch.jhu.edu> <C5uxJ9.pJ@darkside.osrhe.uoknor.edu>',\n",
              "    'NNTP-Posting-Host': ' b64635.student.cwru.edu'},\n",
              "   'In article <C5uxJ9.pJ@darkside.osrhe.uoknor.edu> bil@okcforum.osrhe.edu (Bill Conner) writes:'])]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# en appliquant la meme fonction sur le rdd2\n",
        "new_rdd2=rdd2.map(structuration_document)"
      ],
      "metadata": {
        "id": "cf4484UdAjBv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_rdd2.take(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkW5ltJxAska",
        "outputId": "66ceb24d-8395-4a2c-cb33-076579e4c0b7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('file:/content/20_newsgroups/rec.sport.baseball/104985',\n",
              "  [{'Newsgroups': ' rec.sport.baseball',\n",
              "    'Path': ' cantaloupe.srv.cs.cmu.edu!rochester!udel!gatech!howland.reston.ans.net!zaphod.mps.ohio-state.edu!magnus.acs.ohio-state.edu!dmoney',\n",
              "    'From': ' dmoney@magnus.acs.ohio-state.edu (Dean R Money)',\n",
              "    'Subject': ' The Braves will come around...',\n",
              "    'Message-ID': ' <1993Apr23.193027.26515@magnus.acs.ohio-state.edu>',\n",
              "    'Sender': ' news@magnus.acs.ohio-state.edu',\n",
              "    'Nntp-Posting-Host': ' bottom.magnus.acs.ohio-state.edu',\n",
              "    'Organization': ' The Ohio State University',\n",
              "    'Date': ' Fri, 23 Apr 1993 19:30:27 GMT',\n",
              "    'Lines': ' 28'},\n",
              "   'To all the Braves doubters:']),\n",
              " ('file:/content/20_newsgroups/rec.sport.baseball/104504',\n",
              "  [{'Newsgroups': ' rec.sport.baseball',\n",
              "    'Path': ' cantaloupe.srv.cs.cmu.edu!das-news.harvard.edu!noc.near.net!howland.reston.ans.net!usenet.ins.cwru.edu!wsu-cs!vela.acs.oakland.edu!cs.uiuc.edu!cs.uiuc.edu!steph',\n",
              "    'From': ' steph@cs.uiuc.edu (Dale Stephenson)',\n",
              "    'Subject': ' Defensive Averages 1988-1992, Third Base',\n",
              "    'Message-ID': ' <C5JJrJ.EM3@cs.uiuc.edu>',\n",
              "    'Summary': ' career defensive averages at third',\n",
              "    'Organization': ' University of Illinois, Dept. of Comp. Sci., Urbana, IL',\n",
              "    'Date': ' Thu, 15 Apr 1993 20:04:30 GMT',\n",
              "    'Lines': ' 68'},\n",
              "   'Compiled from the last five Defensive Average reports, here are the career\\nDAs for the individual players in the reports.  Stats are courtesy of\\nSherri Nichols.  Players are listed in descending order.'])]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.6 Fusion des deux new RDD"
      ],
      "metadata": {
        "id": "ARKuwSIW03VA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "en faisant l'union des deux RDD"
      ],
      "metadata": {
        "id": "aXEvPSW2XPmW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fusionner les deux RDD (union)\n",
        "fusion=new_rdd1.union(new_rdd2)"
      ],
      "metadata": {
        "id": "aRn8a57Du1py"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fusion.take(2)"
      ],
      "metadata": {
        "id": "81NjmV3R8kxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de68f0cb-a988-4b38-a766-69b78a095008"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('file:/content/20_newsgroups/alt.atheism/53791',\n",
              "  [{'Xref': ' cantaloupe.srv.cs.cmu.edu alt.atheism:53791 talk.religion.misc:84109 talk.origins:41079',\n",
              "    'Newsgroups': ' alt.atheism,talk.religion.misc,talk.origins',\n",
              "    'Path': ' cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!bb3.andrew.cmu.edu!news.sei.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!zaphod.mps.ohio-state.edu!swrinde!cs.utexas.edu!utnut!torn!nott!cunews!rjg',\n",
              "    'From': ' rjg@doe.carleton.ca (Richard Griffith)',\n",
              "    'Subject': ' Re: Burden of Proof',\n",
              "    'Message-ID': ' <rjg.735427215@wesley>',\n",
              "    'Sender': ' news@cunews.carleton.ca (News Administrator)',\n",
              "    'Organization': ' Dept. of Electronics, Carleton University',\n",
              "    'References': ' <C5t5sF.8oz@mentor.cc.purdue.edu> <1r4b59$7hg@aurora.engr.LaTech.edu>',\n",
              "    'Date': ' Wed, 21 Apr 1993 21:20:15 GMT',\n",
              "    'Lines': ' 23'},\n",
              "   'In <1r4b59$7hg@aurora.engr.LaTech.edu> ray@engr.LaTech.edu (Bill Ray) writes:']),\n",
              " ('file:/content/20_newsgroups/alt.atheism/54220',\n",
              "  [{'Path': ' cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!fs7.ece.cmu.edu!europa.eng.gtefsd.com!howland.reston.ans.net!usenet.ins.cwru.edu!po.CWRU.edu!kmr4',\n",
              "    'From': ' kmr4@po.CWRU.edu (Keith M. Ryan)',\n",
              "    'Newsgroups': ' alt.atheism',\n",
              "    'Subject': ' Re: free moral agency',\n",
              "    'Date': ' Thu, 22 Apr 1993 23:48:54 GMT',\n",
              "    'Organization': ' Case Western Reserve University',\n",
              "    'Lines': ' 29',\n",
              "    'Message-ID': ' <kmr4.1678.735522534@po.CWRU.edu>',\n",
              "    'References': ' <1993Apr19.161248.23708@welchgate.welch.jhu.edu> <C5uxJ9.pJ@darkside.osrhe.uoknor.edu>',\n",
              "    'NNTP-Posting-Host': ' b64635.student.cwru.edu'},\n",
              "   'In article <C5uxJ9.pJ@darkside.osrhe.uoknor.edu> bil@okcforum.osrhe.edu (Bill Conner) writes:'])]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.7 Transformation le nouveau RDD obtenu pour que chaque élément soit de type pyspark.sql.Row"
      ],
      "metadata": {
        "id": "gi0LvfR7u2iU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import Row\n",
        "\n",
        "# cette fonction ToRow est utilisée pour manipuler la table sql et faire des requetes.\n",
        "def ToRow(x):\n",
        "  entete=x[1][0]\n",
        "  \n",
        "  #Certains éléments (comme Subject ou Date) n'éxistent pas dans tous les documents\n",
        "  #C'est pour cela que la création du dictionnaire avec la fonction structuration_document() va nous aider dans les tests d'éxistance\n",
        "  row = Row(Path=x[0], Newsgroups=entete['Newsgroups'] if 'Newsgroups' in entete.keys() else None,\n",
        "            Organization=entete['Organization'] if 'Organization' in entete.keys() else None,\n",
        "            Subject=entete['Subject'] if 'Subject' in entete.keys() else None,\n",
        "            Date=entete['Date'] if 'Date' in entete.keys() else None,\n",
        "            Lines=entete['Lines'] if 'Lines' in entete.keys() else None,\n",
        "            From=entete['From'] if 'From' in entete.keys() else None,\n",
        "\n",
        "            Contenu=x[1][1])\n",
        "  \n",
        "  return row\n",
        "\n",
        "rddF=fusion.map(ToRow)\n"
      ],
      "metadata": {
        "id": "DcArLax4vGn3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rddF.take(2)"
      ],
      "metadata": {
        "id": "WMSB87g_x4DG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9d7f4c4-e80e-4eed-9419-63716a0ad117"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(Path='file:/content/20_newsgroups/alt.atheism/53791', Newsgroups=' alt.atheism,talk.religion.misc,talk.origins', Organization=' Dept. of Electronics, Carleton University', Subject=' Re: Burden of Proof', Date=' Wed, 21 Apr 1993 21:20:15 GMT', Lines=' 23', From=' rjg@doe.carleton.ca (Richard Griffith)', Contenu='In <1r4b59$7hg@aurora.engr.LaTech.edu> ray@engr.LaTech.edu (Bill Ray) writes:'),\n",
              " Row(Path='file:/content/20_newsgroups/alt.atheism/54220', Newsgroups=' alt.atheism', Organization=' Case Western Reserve University', Subject=' Re: free moral agency', Date=' Thu, 22 Apr 1993 23:48:54 GMT', Lines=' 29', From=' kmr4@po.CWRU.edu (Keith M. Ryan)', Contenu='In article <C5uxJ9.pJ@darkside.osrhe.uoknor.edu> bil@okcforum.osrhe.edu (Bill Conner) writes:')]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.8 Création d'unobjet de type DataFrame à partir du RDD fusionné"
      ],
      "metadata": {
        "id": "7OxFVFKbYNOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dataframe spark\n",
        "df=spark.createDataFrame(rddF)\n",
        "df.printSchema()\n",
        "df.show()\n",
        "df.count()"
      ],
      "metadata": {
        "id": "jkNhg-JGyrsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d4af20-591e-452e-f11e-ae6256403034"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Path: string (nullable = true)\n",
            " |-- Newsgroups: string (nullable = true)\n",
            " |-- Organization: string (nullable = true)\n",
            " |-- Subject: string (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Lines: string (nullable = true)\n",
            " |-- From: string (nullable = true)\n",
            " |-- Contenu: string (nullable = true)\n",
            "\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+\n",
            "|                Path|          Newsgroups|        Organization|             Subject|                Date|Lines|                From|             Contenu|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+\n",
            "|file:/content/20_...| alt.atheism,talk...| Dept. of Electro...| Re: Burden of Proof| Wed, 21 Apr 1993...|   23| rjg@doe.carleton...|In <1r4b59$7hg@au...|\n",
            "|file:/content/20_...|         alt.atheism| Case Western Res...| Re: free moral a...| Thu, 22 Apr 1993...|   29| kmr4@po.CWRU.edu...|In article <C5uxJ...|\n",
            "|file:/content/20_...|         alt.atheism| California Insti...| Re: >>>>>>Pompou...| 2 Apr 93 21:01:4...|   14| keith@cco.caltec...|livesey@solntze.w...|\n",
            "|file:/content/20_...|         alt.atheism| Decision Support...| Re: Yet more Rus...| 26 Apr 1993 11:0...|   28| perry@dsinc.com ...|In article <1993A...|\n",
            "|file:/content/20_...|         alt.atheism| Welch Medical Li...| Re: A Little Too...| Mon, 5 Apr 1993 ...|   21| davidk@welch.jhu...|In article 65934@...|\n",
            "|file:/content/20_...|         alt.atheism|                null| Re: Amusing athe...| 20 Apr 93 08:31:...|  117| timmbake@mcl.ucs...|mccullou@whipple....|\n",
            "|file:/content/20_...|         alt.atheism| Decision Support...| Re: Who Says the...| 20 Apr 1993 13:3...|   30| perry@dsinc.com ...|Another article t...|\n",
            "|file:/content/20_...|         alt.atheism|                null|    More Best of A.A| 24 Apr 93 00:01:...|  164| bobbe@vice (Robe...|                    |\n",
            "|file:/content/20_...| sci.skeptic,alt....| University of Ma...|    Re: Asimov stamp| Fri, 23 Apr 1993...|   23| rsrodger@wam.umd...|In article <schni...|\n",
            "|file:/content/20_...| alt.atheism,talk...|  Indiana University| Re: The Universe...| Wed, 21 Apr 1993...|   69| battin@cyclops.i...|On re-reading thi...|\n",
            "|file:/content/20_...|         alt.atheism|  Siemens-Nixdorf AG| Re: Societal bas...| 21 Apr 1993 10:3...|   49| frank@D012S658.u...|In article <1993A...|\n",
            "|file:/content/20_...|         alt.atheism|                 sgi| Re: Slavery (was...| 16 Apr 1993 05:5...|   37| livesey@solntze....|In article <1993A...|\n",
            "|file:/content/20_...|         alt.atheism|                 sgi| Re: Morality? (w...| 16 Apr 1993 06:0...|   93| livesey@solntze....|In article <1qlet...|\n",
            "|file:/content/20_...|         alt.atheism| Decision Support...| Re: Is Morality ...| 20 Apr 1993 13:2...|   99| perry@dsinc.com ...|My last response ...|\n",
            "|file:/content/20_...|         alt.atheism| Monash Universit...| Re: Yet more Rus...| Tue, 6 Apr 1993 ...|  131| darice@yoyo.cc.m...|In <2942956021.3....|\n",
            "|file:/content/20_...|         alt.atheism| California Insti...| Re: Is Keith as ...| 4 Apr 1993 08:33...|   16| keith@cco.caltec...|mam@mouse.cmhnet....|\n",
            "|file:/content/20_...|         alt.atheism| ITC, Griffith Un...| Re: Societally a...| 21 Apr 93 00:54:...|   49| ednclark@kraken....|cobb@alexia.lis.u...|\n",
            "|file:/content/20_...|         alt.atheism|                null| Re: Amusing athe...| 20 Apr 93 00:59:...|   66| timmbake@mcl.ucs...|\\nJames Hogan wri...|\n",
            "|file:/content/20_...|         alt.atheism| Technical Univer...|     Re: Yeah, Right| Tue, 6 Apr 1993 ...|   54| I3150101@dbstu1....|In article <66014...|\n",
            "|file:/content/20_...|         alt.atheism| Tektronix Inc., ...| Re: Yet more Rus...| 16 Apr 93 04:42:...|   25| bobbe@vice.ICO.T...|In article <11556...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.9 Sauvegarde la DataFrame au format Avro"
      ],
      "metadata": {
        "id": "_ByCPIPHYd01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_p1cLdoi18Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandavro"
      ],
      "metadata": {
        "id": "9j4F1Md60WZu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "240ff9b8-3bce-4a22-c4bd-db8adc6ecd72"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandavro\n",
            "  Downloading pandavro-1.7.1.tar.gz (8.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fastavro==1.5.1\n",
            "  Downloading fastavro-1.5.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.8/dist-packages (from pandavro) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.8/dist-packages (from pandavro) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1->pandavro) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1->pandavro) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1->pandavro) (1.15.0)\n",
            "Building wheels for collected packages: pandavro\n",
            "  Building wheel for pandavro (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandavro: filename=pandavro-1.7.1-py3-none-any.whl size=5688 sha256=59d4e81ee874531b44aeacb6f4c85f1113387fcc011bfe419965cf015dca116a\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/cc/15/480a3cfa1a9fc49e2af9bde7437bd6c8c0265f17e61f32672b\n",
            "Successfully built pandavro\n",
            "Installing collected packages: fastavro, pandavro\n",
            "Successfully installed fastavro-1.5.1 pandavro-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandavro as pdx\n",
        "from pyspark.sql.avro.functions import from_avro, to_avro\n",
        "filename = \"df.avro\"\n",
        "# on a passé par le dataframe pandas mais ça envoie tout au driver\n",
        "df2=df.toPandas()\n",
        "pdx.to_avro(filename, df2)\n",
        "#df.write.partitionBy(\"Path\",).avro(\"output_dir\")\n",
        "#avroDf = df.select(to_avro(df.Path).alias(\"avro\"))\n",
        "#avroDf.collect()"
      ],
      "metadata": {
        "id": "t2smBRf61WTP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lecture du fichier avro créé\n",
        "saved = pdx.read_avro(filename)\n"
      ],
      "metadata": {
        "id": "45jc0cIg44-4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.10 Sauvegarder la DataFrame au format Parquet"
      ],
      "metadata": {
        "id": "SkHqZdwqYsFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sauvgarder le dataframe au format parquet\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "table = pa.Table.from_pandas(df2)\n",
        "pq.write_table(table, 'df.parquet')"
      ],
      "metadata": {
        "id": "ukrDrjxH4L0x"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test: lecture du df a partir du fichier parquet\n",
        "table2 = pq.read_table('df.parquet')\n",
        "table2.to_pandas()"
      ],
      "metadata": {
        "id": "BVWBv2Tk4pRG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "72cae2c7-d00e-4c2d-9e0c-8abbff36c8c2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Path  \\\n",
              "0         file:/content/20_newsgroups/alt.atheism/53791   \n",
              "1         file:/content/20_newsgroups/alt.atheism/54220   \n",
              "2         file:/content/20_newsgroups/alt.atheism/51127   \n",
              "3         file:/content/20_newsgroups/alt.atheism/54191   \n",
              "4         file:/content/20_newsgroups/alt.atheism/51225   \n",
              "...                                                 ...   \n",
              "1995  file:/content/20_newsgroups/rec.sport.baseball...   \n",
              "1996  file:/content/20_newsgroups/rec.sport.baseball...   \n",
              "1997  file:/content/20_newsgroups/rec.sport.baseball...   \n",
              "1998  file:/content/20_newsgroups/rec.sport.baseball...   \n",
              "1999  file:/content/20_newsgroups/rec.sport.baseball...   \n",
              "\n",
              "                                        Newsgroups  \\\n",
              "0      alt.atheism,talk.religion.misc,talk.origins   \n",
              "1                                      alt.atheism   \n",
              "2                                      alt.atheism   \n",
              "3                                      alt.atheism   \n",
              "4                                      alt.atheism   \n",
              "...                                            ...   \n",
              "1995                            rec.sport.baseball   \n",
              "1996                            rec.sport.baseball   \n",
              "1997                            rec.sport.baseball   \n",
              "1998                            rec.sport.baseball   \n",
              "1999                            rec.sport.baseball   \n",
              "\n",
              "                                       Organization  \\\n",
              "0         Dept. of Electronics, Carleton University   \n",
              "1                   Case Western Reserve University   \n",
              "2      California Institute of Technology, Pasadena   \n",
              "3                             Decision Support Inc.   \n",
              "4                             Welch Medical Library   \n",
              "...                                             ...   \n",
              "1995                The Cleveland Clinic Foundation   \n",
              "1996               University of Illinois at Urbana   \n",
              "1997                  Kendall Square Research Corp.   \n",
              "1998                       University of Washington   \n",
              "1999                     Adobe Systems Incorporated   \n",
              "\n",
              "                                                Subject  \\\n",
              "0                                   Re: Burden of Proof   \n",
              "1                                 Re: free moral agency   \n",
              "2                                 Re: >>>>>>Pompous ass   \n",
              "3                Re: Yet more Rushdie [Re: ISLAMIC LAW]   \n",
              "4                              Re: A Little Too Satanic   \n",
              "...                                                 ...   \n",
              "1995                               Re: Wounded Redbirds   \n",
              "1996                                       Re: Moe Berg   \n",
              "1997                Texas Rangers Roster - PLEASE HELP!   \n",
              "1998                                   Re: New Uniforms   \n",
              "1999   Re: OBP hurt by sac flies (was Re: HBP? BB? B...   \n",
              "\n",
              "                                Date Lines  \\\n",
              "0      Wed, 21 Apr 1993 21:20:15 GMT    23   \n",
              "1      Thu, 22 Apr 1993 23:48:54 GMT    29   \n",
              "2              2 Apr 93 21:01:40 GMT    14   \n",
              "3         26 Apr 1993 11:08:49 -0400    28   \n",
              "4       Mon, 5 Apr 1993 13:34:38 GMT    21   \n",
              "...                              ...   ...   \n",
              "1995   Wed, 21 Apr 1993 17:23:28 GMT     7   \n",
              "1996   Tue, 20 Apr 1993 18:10:13 GMT    31   \n",
              "1997          20 Apr 93 12:55:09 EDT    19   \n",
              "1998           6 Apr 93 17:32:36 GMT    16   \n",
              "1999   Fri, 23 Apr 1993 15:54:05 GMT    16   \n",
              "\n",
              "                                                  From  \\\n",
              "0               rjg@doe.carleton.ca (Richard Griffith)   \n",
              "1                     kmr4@po.CWRU.edu (Keith M. Ryan)   \n",
              "2        keith@cco.caltech.edu (Keith Allan Schneider)   \n",
              "3                          perry@dsinc.com (Jim Perry)   \n",
              "4       davidk@welch.jhu.edu (David \"Go-Go\" Kitaguchi)   \n",
              "...                                                ...   \n",
              "1995                tknuth@bio.ri.ccf.org (Todd Knuth)   \n",
              "1996             rkoffler@ux4.cso.uiuc.edu (Bighelmet)   \n",
              "1997                         dorin@ksr.com (Bob Dorin)   \n",
              "1998   neuharth@hardy.u.washington.edu (John Neuharth)   \n",
              "1999               snichols@adobe.com (Sherri Nichols)   \n",
              "\n",
              "                                                Contenu  \n",
              "0     In <1r4b59$7hg@aurora.engr.LaTech.edu> ray@eng...  \n",
              "1     In article <C5uxJ9.pJ@darkside.osrhe.uoknor.ed...  \n",
              "2     livesey@solntze.wpd.sgi.com (Jon Livesey) writes:  \n",
              "3     In article <1993Apr25.031703.5230@monu6.cc.mon...  \n",
              "4     In article 65934@mimsy.umd.edu, mangoe@cs.umd....  \n",
              "...                                                 ...  \n",
              "1995  In article 1@acad.drake.edu, sbp002@acad.drake...  \n",
              "1996  barring@cs.washington.edu (David Barrington) w...  \n",
              "1997  I need a little help from a Texas Rangers expert.  \n",
              "1998         jpopovich@guvax.acc.georgetown.edu writes:  \n",
              "1999  In article <1993Apr23.065059.16619@rigel.econ....  \n",
              "\n",
              "[2000 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5aa1d0ac-49c8-4614-8e87-7e98742edf7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Path</th>\n",
              "      <th>Newsgroups</th>\n",
              "      <th>Organization</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Date</th>\n",
              "      <th>Lines</th>\n",
              "      <th>From</th>\n",
              "      <th>Contenu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>file:/content/20_newsgroups/alt.atheism/53791</td>\n",
              "      <td>alt.atheism,talk.religion.misc,talk.origins</td>\n",
              "      <td>Dept. of Electronics, Carleton University</td>\n",
              "      <td>Re: Burden of Proof</td>\n",
              "      <td>Wed, 21 Apr 1993 21:20:15 GMT</td>\n",
              "      <td>23</td>\n",
              "      <td>rjg@doe.carleton.ca (Richard Griffith)</td>\n",
              "      <td>In &lt;1r4b59$7hg@aurora.engr.LaTech.edu&gt; ray@eng...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>file:/content/20_newsgroups/alt.atheism/54220</td>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>Case Western Reserve University</td>\n",
              "      <td>Re: free moral agency</td>\n",
              "      <td>Thu, 22 Apr 1993 23:48:54 GMT</td>\n",
              "      <td>29</td>\n",
              "      <td>kmr4@po.CWRU.edu (Keith M. Ryan)</td>\n",
              "      <td>In article &lt;C5uxJ9.pJ@darkside.osrhe.uoknor.ed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>file:/content/20_newsgroups/alt.atheism/51127</td>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>California Institute of Technology, Pasadena</td>\n",
              "      <td>Re: &gt;&gt;&gt;&gt;&gt;&gt;Pompous ass</td>\n",
              "      <td>2 Apr 93 21:01:40 GMT</td>\n",
              "      <td>14</td>\n",
              "      <td>keith@cco.caltech.edu (Keith Allan Schneider)</td>\n",
              "      <td>livesey@solntze.wpd.sgi.com (Jon Livesey) writes:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>file:/content/20_newsgroups/alt.atheism/54191</td>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>Decision Support Inc.</td>\n",
              "      <td>Re: Yet more Rushdie [Re: ISLAMIC LAW]</td>\n",
              "      <td>26 Apr 1993 11:08:49 -0400</td>\n",
              "      <td>28</td>\n",
              "      <td>perry@dsinc.com (Jim Perry)</td>\n",
              "      <td>In article &lt;1993Apr25.031703.5230@monu6.cc.mon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>file:/content/20_newsgroups/alt.atheism/51225</td>\n",
              "      <td>alt.atheism</td>\n",
              "      <td>Welch Medical Library</td>\n",
              "      <td>Re: A Little Too Satanic</td>\n",
              "      <td>Mon, 5 Apr 1993 13:34:38 GMT</td>\n",
              "      <td>21</td>\n",
              "      <td>davidk@welch.jhu.edu (David \"Go-Go\" Kitaguchi)</td>\n",
              "      <td>In article 65934@mimsy.umd.edu, mangoe@cs.umd....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>file:/content/20_newsgroups/rec.sport.baseball...</td>\n",
              "      <td>rec.sport.baseball</td>\n",
              "      <td>The Cleveland Clinic Foundation</td>\n",
              "      <td>Re: Wounded Redbirds</td>\n",
              "      <td>Wed, 21 Apr 1993 17:23:28 GMT</td>\n",
              "      <td>7</td>\n",
              "      <td>tknuth@bio.ri.ccf.org (Todd Knuth)</td>\n",
              "      <td>In article 1@acad.drake.edu, sbp002@acad.drake...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>file:/content/20_newsgroups/rec.sport.baseball...</td>\n",
              "      <td>rec.sport.baseball</td>\n",
              "      <td>University of Illinois at Urbana</td>\n",
              "      <td>Re: Moe Berg</td>\n",
              "      <td>Tue, 20 Apr 1993 18:10:13 GMT</td>\n",
              "      <td>31</td>\n",
              "      <td>rkoffler@ux4.cso.uiuc.edu (Bighelmet)</td>\n",
              "      <td>barring@cs.washington.edu (David Barrington) w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>file:/content/20_newsgroups/rec.sport.baseball...</td>\n",
              "      <td>rec.sport.baseball</td>\n",
              "      <td>Kendall Square Research Corp.</td>\n",
              "      <td>Texas Rangers Roster - PLEASE HELP!</td>\n",
              "      <td>20 Apr 93 12:55:09 EDT</td>\n",
              "      <td>19</td>\n",
              "      <td>dorin@ksr.com (Bob Dorin)</td>\n",
              "      <td>I need a little help from a Texas Rangers expert.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>file:/content/20_newsgroups/rec.sport.baseball...</td>\n",
              "      <td>rec.sport.baseball</td>\n",
              "      <td>University of Washington</td>\n",
              "      <td>Re: New Uniforms</td>\n",
              "      <td>6 Apr 93 17:32:36 GMT</td>\n",
              "      <td>16</td>\n",
              "      <td>neuharth@hardy.u.washington.edu (John Neuharth)</td>\n",
              "      <td>jpopovich@guvax.acc.georgetown.edu writes:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>file:/content/20_newsgroups/rec.sport.baseball...</td>\n",
              "      <td>rec.sport.baseball</td>\n",
              "      <td>Adobe Systems Incorporated</td>\n",
              "      <td>Re: OBP hurt by sac flies (was Re: HBP? BB? B...</td>\n",
              "      <td>Fri, 23 Apr 1993 15:54:05 GMT</td>\n",
              "      <td>16</td>\n",
              "      <td>snichols@adobe.com (Sherri Nichols)</td>\n",
              "      <td>In article &lt;1993Apr23.065059.16619@rigel.econ....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5aa1d0ac-49c8-4614-8e87-7e98742edf7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5aa1d0ac-49c8-4614-8e87-7e98742edf7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5aa1d0ac-49c8-4614-8e87-7e98742edf7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 Analyse descriptive API SPARK SQL"
      ],
      "metadata": {
        "id": "I2y9zdHaY_2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Vérification de deux catégories différentes de documents"
      ],
      "metadata": {
        "id": "Dx2QZTJ9ZdpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# le nombre de documents par Newsgroups\n",
        "df.groupBy(\"Newsgroups\").count().show()"
      ],
      "metadata": {
        "id": "7hpRl_hC6xaT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb412eeb-f784-4f79-bab3-95f748b05248"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|          Newsgroups|count|\n",
            "+--------------------+-----+\n",
            "| talk.religion.mi...|    2|\n",
            "| sci.skeptic,alt....|    7|\n",
            "| alt.atheism,soc....|    1|\n",
            "| talk.abortion,al...|    1|\n",
            "| alt.atheism,talk...|    3|\n",
            "| alt.atheism,rec....|    3|\n",
            "| alt.atheism,talk...|   92|\n",
            "| rec.scouting,soc...|    1|\n",
            "| soc.culture.arab...|    2|\n",
            "| alt.atheism,talk...|    5|\n",
            "| alt.atheism,alt....|    2|\n",
            "| alt.atheism,soc....|    8|\n",
            "|         alt.atheism|  734|\n",
            "| alt.atheism,alt....|    7|\n",
            "| talk.religion.mi...|    4|\n",
            "| alt.atheism,talk...|   20|\n",
            "| alt.slack,talk.r...|    1|\n",
            "| talk.religion.mi...|    4|\n",
            "| talk.abortion,al...|   94|\n",
            "| alt.atheism,soc....|    2|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On remarque que le champ Newsgroups peut contenir des éléments en plus des deux catégories principales \"alt.atheism\" ou \"rec.sport.baseball\".\n",
        "\n",
        "Pour vérifier qu'on a bien ces deux catégories principales différentes, nous allons créer deux vues: \n",
        "\n",
        "* Une vue `sport` qui contient toutes les lignes ou `rec.sport.baseball` apparait.\n",
        "* Une vue `religion` qui contient toutes les lignes ou `alt.atheism` apparait.\n",
        "\n",
        "Puis nous allons compter le nombre d'éléments dans chaque liste, en plus de voir si l'intersectiondes deux vues est vide ou pas.\n",
        "\n",
        "Si l'intersection est vide, et que la somme des éléments des deux vues est égales au nombre total des éléments de la fusion, cela veut dire que les documents sont bien separés par deux catégories principales  \"alt.atheism\" et \"rec.sport.baseball\"."
      ],
      "metadata": {
        "id": "-hLXilk-4ROA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mettre le dataframe dans une table sql (Document)\n",
        "\n",
        "from pandas._libs.hashtable import value_count\n",
        "df.createOrReplaceTempView(\"Document\")"
      ],
      "metadata": {
        "id": "B4I4EBSRJAML"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Si les vues sont déja crées\n",
        "#spark.sql(\"DROP VIEW sport\")\n",
        "#spark.sql(\"DROP VIEW religion\")"
      ],
      "metadata": {
        "id": "q_Ba_aJ3ddv7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Création d'une vue (sport) contennat tous les document de catégorie rec.sport.baseball\n",
        "sqlDF = spark.sql(\"CREATE TEMP VIEW sport AS SELECT Newsgroups FROM Document WHERE Newsgroups LIKE '%rec.sport.baseball%'\")"
      ],
      "metadata": {
        "id": "w-BQb23nnvFN"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Création d'une vue (religion) contennat tous les document de catégorie alt.atheism\n",
        "sqlDF = spark.sql(\"CREATE TEMP VIEW religion AS SELECT Newsgroups FROM Document WHERE Newsgroups LIKE '%alt.atheism%'\")"
      ],
      "metadata": {
        "id": "PidZcL3QcW1I"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# affichage la vue Sport\n",
        "sqlDF2 = spark.sql(\"SELECT * FROM sport\")\n",
        "sqlDF2.show()"
      ],
      "metadata": {
        "id": "nu-RhzMfapKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "610cf459-59a6-4a0c-e13a-322f4d280d1c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|          Newsgroups|\n",
            "+--------------------+\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "| rec.sport.baseba...|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "|  rec.sport.baseball|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Affichage la vue religion\n",
        "sqlDF3 = spark.sql(\"SELECT * FROM religion\")\n",
        "sqlDF3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apuqW9XR0gNw",
        "outputId": "4795f8ed-1095-4b7f-a663-236b848ab4dd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|          Newsgroups|\n",
            "+--------------------+\n",
            "| alt.atheism,talk...|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "| sci.skeptic,alt....|\n",
            "| alt.atheism,talk...|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "|         alt.atheism|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# le nombre de documents dont la categorie contient rec_baseball\n",
        "sqlDF3 = spark.sql(\"SELECT count(s.Newsgroups) as nbr_rec_baseball FROM sport s \")\n",
        "sqlDF3.show()"
      ],
      "metadata": {
        "id": "OAUHkV1ne0-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c06f2e41-854a-45ca-d8e8-dbf7236bf286"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|nbr_rec_baseball|\n",
            "+----------------+\n",
            "|            1000|\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# le nombre de documents dont la categorie contient alt.atheism\n",
        "sqlDF3 = spark.sql(\"SELECT count(Newsgroups) as nb_alt_atheism FROM religion\")\n",
        "sqlDF3.show()\n",
        " "
      ],
      "metadata": {
        "id": "y1Ks8dqpgrFN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4caebf-5745-4e27-dda1-cedcc38a769e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+\n",
            "|nb_alt_atheism|\n",
            "+--------------+\n",
            "|          1000|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pour prouver qu'il n'y a pas d'intersection entre les deux catégories \n",
        "# de plus on a 1000 lignes dans la vue religion et 1000 dans la vue religion\n",
        "#(en sachant que le nombre total des lignes dans la table document est de 2000)\n",
        "sqlDF3 = spark.sql(\"SELECT * FROM religion INTERSECT (SELECT * FROM sport) \")\n",
        "sqlDF3.show()"
      ],
      "metadata": {
        "id": "t2Ef-PVLcvUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe76509d-ef67-4b3b-e2f7-7f00ca8a262f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|Newsgroups|\n",
            "+----------+\n",
            "+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion:** on a bien deux catégories différentes de documents"
      ],
      "metadata": {
        "id": "SO3ky_686HRK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 le nombre d'organisations différentes"
      ],
      "metadata": {
        "id": "U7nR0HplZqua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#le nombre d'organisations différentes\n",
        "from pyspark.sql.functions import countDistinct\n",
        "df2=df.select(countDistinct(\"Organization\"))\n",
        "df2.show()"
      ],
      "metadata": {
        "id": "sBrfqeMXhbPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f00ad5-40b5-464a-cc8c-193c4adf0169"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+\n",
            "|count(DISTINCT Organization)|\n",
            "+----------------------------+\n",
            "|                         485|\n",
            "+----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 D’autres statistiques descriptives"
      ],
      "metadata": {
        "id": "1UCqke2mZ0H8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max, Min , Moyenne par rapport a l'attribut Lines"
      ],
      "metadata": {
        "id": "BOdoHH4j6ai_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe(\"Lines\").show()"
      ],
      "metadata": {
        "id": "JYV_xrQNjD80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17c20b40-efca-4b95-dc3c-d2179729a96f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+\n",
            "|summary|            Lines|\n",
            "+-------+-----------------+\n",
            "|  count|             1994|\n",
            "|   mean|36.48294884653962|\n",
            "| stddev|48.79137273450094|\n",
            "|    min|                1|\n",
            "|    max|               99|\n",
            "+-------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le nombre de documents par organization"
      ],
      "metadata": {
        "id": "a6afe-ID6dxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"Organization\").count().show()"
      ],
      "metadata": {
        "id": "sHfV1q3gkOt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cad5a9d-6553-485e-efa3-8646bc8e3163"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|        Organization|count|\n",
            "+--------------------+-----+\n",
            "|           SunSelect|    2|\n",
            "| Case Western Res...|   39|\n",
            "| Princeton Univer...|   24|\n",
            "| University of Ne...|    2|\n",
            "| S-CUBED, A Divis...|    1|\n",
            "| Harlequin Ltd. C...|    1|\n",
            "| University of Ne...|    7|\n",
            "|   Cured, discharged|    3|\n",
            "|   Augustana College|    1|\n",
            "| National Optical...|    2|\n",
            "| Dept. of Electro...|    1|\n",
            "| Cabletron System...|    6|\n",
            "| Welch Medical Li...|    2|\n",
            "| Red Wolfe @ The ...|    1|\n",
            "|  Indiana University|   17|\n",
            "| Johns Hopkins Un...|    7|\n",
            "| Okcforum Unix Us...|   32|\n",
            "| Iowa State Unive...|    2|\n",
            "| Wesleyan University|    7|\n",
            "| Tektronix, Inc.,...|   11|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le nombre de documents qui ont été créés pour chaque auteur"
      ],
      "metadata": {
        "id": "l3GPYGJe6hFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"FROM\").count().show()"
      ],
      "metadata": {
        "id": "-E-v5GPmoOgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19366e7d-aa5d-411f-a3d2-a0157c89472c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|                FROM|count|\n",
            "+--------------------+-----+\n",
            "| dpw@sei.cmu.edu ...|    4|\n",
            "| mccullou@snake2....|    6|\n",
            "| livesey@solntze....|   70|\n",
            "| markp@avignon (M...|    1|\n",
            "| jvigneau@cs.ulow...|    1|\n",
            "| kilman2y@fiu.edu...|    1|\n",
            "| darice@yoyo.cc.m...|   14|\n",
            "| cust_ts@klaava.H...|    2|\n",
            "| kax@cs.nott.ac.u...|    2|\n",
            "| acooper@mac.cc.m...|    4|\n",
            "| \"James F. Tims\" ...|    1|\n",
            "| kutluk@ccl.umist...|    1|\n",
            "| <MVS104@psuvm.ps...|    1|\n",
            "| davec@silicon.cs...|    1|\n",
            "| halat@pooh.bears...|   15|\n",
            "| nancyo@shnext15....|    1|\n",
            "| David O Hunt <bl...|    1|\n",
            "| sbradley@scic.in...|    2|\n",
            "| mikec@sail.LABS....|    2|\n",
            "| adpeters@sunflow...|    3|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.A. Transformation de texte : Tout le document\n",
        "Dans ce qui suit, nous allons créer un nouvel RDD de type pyspark.sql.Row puis un dataframe qui a une seule colonne contenant tout le document. Ceci est pour faire un premier test sur l'algorithme KMeans.\n"
      ],
      "metadata": {
        "id": "7AZiuZ0y0sv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ToRow_all_document(x):\n",
        "  entete=x[1][0]\n",
        "  val=\" \".join(entete.values())\n",
        "\n",
        "  row = Row(document=val+x[1][1])\n",
        "  return row\n",
        "\n",
        "all_document=fusion.map(ToRow_all_document)"
      ],
      "metadata": {
        "id": "lye_X9uCv9AJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create spark dataframe contenant tout le document\n",
        "all_document_df=spark.createDataFrame(all_document)\n",
        "all_document_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZP0R_NlxVK_",
        "outputId": "d9dfff5e-f56d-4567-ec5d-5189cf430705"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- document: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformation du Texte\n",
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
      ],
      "metadata": {
        "id": "5ypsFYwSwBQt"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.A.2 Découpage les documents en listes de mots à l’aide de Tokenizer"
      ],
      "metadata": {
        "id": "28pgScGqaCbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(inputCol=\"document\", outputCol=\"words\")\n",
        "#d=df.select(\"Contenu\")\n",
        "wordsData = tokenizer.transform(all_document_df)\n",
        "wordsData.show()"
      ],
      "metadata": {
        "id": "UK5E3PKY1PWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6584924-a5a2-4672-fb30-1c371496c987"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+\n",
            "|            document|               words|\n",
            "+--------------------+--------------------+\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|\n",
            "+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.A.3 Création d'une représentation vectorielle des documents à l’aide de HashingTF"
      ],
      "metadata": {
        "id": "GuOk1oW9aHEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Création d'une représentation vectorielle des documents à l’aide de HashingTF\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"features_hache\", numFeatures=20)\n",
        "featurizedData = hashingTF.transform(wordsData)\n",
        "featurizedData.show()"
      ],
      "metadata": {
        "id": "AN7U4yd4-noE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e1ebb0-29d4-4b96-a385-1878c9896341"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+\n",
            "|            document|               words|      features_hache|\n",
            "+--------------------+--------------------+--------------------+\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,5,6,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,2,3,4,5,6,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[1,2,5,6,7,9,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,2,3,4,5,6,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,2,3,4,5,6,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[2,4,5,7,8,9,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|(20,[0,1,2,3,5,6,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,2,3,5,6,7,...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|(20,[1,2,4,5,6,7,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[1,2,4,5,9,10...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|\n",
            "+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6-7.A. Groupement des documents ayants des représentations vectorielles proches"
      ],
      "metadata": {
        "id": "64x2h5gset1i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###A.1. KMeans avec la pondération Tf-Idf"
      ],
      "metadata": {
        "id": "mHo24suplrmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pondération des mots avec la formule Tf-*Idf*"
      ],
      "metadata": {
        "id": "-w3WH3fRfcip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "idf = IDF(inputCol=\"features_hache\", outputCol=\"features\")\n",
        "idfModel = idf.fit(featurizedData)\n",
        "rescaledData = idfModel.transform(featurizedData)\n",
        "rescaledData.show()"
      ],
      "metadata": {
        "id": "fN4gfyADC4Q3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0b05235-f03c-4ed2-c1b1-8ad138378085"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "|            document|               words|      features_hache|            features|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,5,6,...|(20,[0,1,2,3,5,6,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,2,3,4,5,6,...|(20,[0,2,3,4,5,6,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[1,2,5,6,7,9,...|(20,[1,2,5,6,7,9,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,2,3,4,5,6,...|(20,[0,2,3,4,5,6,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,2,3,4,5,6,...|(20,[0,2,3,4,5,6,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[2,4,5,7,8,9,...|(20,[2,4,5,7,8,9,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|(20,[0,1,2,3,5,6,...|(20,[0,1,2,3,5,6,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,2,3,5,6,7,...|(20,[0,2,3,5,6,7,...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|(20,[1,2,4,5,6,7,...|(20,[1,2,4,5,6,7,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[1,2,4,5,9,10...|(20,[1,2,4,5,9,10...|\n",
            "| alt.atheism  can...|[, alt.atheism, ,...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
            "| cantaloupe.srv.c...|[, cantaloupe.srv...|(20,[0,1,2,3,4,5,...|(20,[0,1,2,3,4,5,...|\n",
            "+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### KMeans avec ponderation Tf-Idf"
      ],
      "metadata": {
        "id": "oM4fMHZvfobR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comme nous allons tester l'algorithme de KMeans dans plusieurs cas (document entier/entete et Tf-Idf/normalisation), nous allons créer une fonction K_means qui prend un vecteur et applique l'algorithme de clustering dessus, puis affiche le Silhouette score, le nombre de clusters, leurs centres et la taille de chaque cluster."
      ],
      "metadata": {
        "id": "pCbsG5lSkBd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kmeans  \n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "\n",
        "\n",
        "def K_means(Datavector):\n",
        "    # Trains a k-means model.\n",
        "    kmeans = KMeans().setK(2).setSeed(5)\n",
        "    model = kmeans.fit(Datavector)\n",
        "    # make prediction\n",
        "    predictions = model.transform(Datavector)\n",
        "    # Evaluate clustering by computing Silhouette score\n",
        "    evaluator = ClusteringEvaluator()\n",
        "\n",
        "    # Le Silhouette score est une mesure utilisée pour calculer la qualité technique du clustering , sa valeur est comprise entre 1 et -1\n",
        "    # 1: un bon clustering\n",
        "    # 0: Signifie que les clusters sont indifférents, ou nous pouvons dire que la distance entre les clusters n'est pas significative.\n",
        "    # -1: Signifie que les clusters sont affectés dans le mauvais sens.\n",
        "    # s=(ba)/max(a,b) ou a est la distance intra-cluster moyenne et b est la distance inter-cluster moyenne\n",
        "\n",
        "    silhouette = evaluator.evaluate(predictions)\n",
        "    print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
        "    # Shows the result.\n",
        "    centers = model.clusterCenters()\n",
        "    print(\"Cluster Centers: \", len(centers))\n",
        "    for center in centers:\n",
        "      print(center)\n",
        "\n",
        "    #Affichage du résultat du clustering\n",
        "    predictions.groupBy('prediction').count().show()"
      ],
      "metadata": {
        "id": "C_fPxQAN2lIJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Kmeans pour idf\n",
        "K_means(rescaledData)"
      ],
      "metadata": {
        "id": "gZlipbA59Dmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***A REVOIR CETTE PARTIE***\n",
        "\n",
        "Le Silhouette score est une métrique allant de -1 à 1. Le score obtenu est donc quasi maximal.\n",
        "\n",
        "Le modèle a trouvé deux clusters bien espacés mais la quasi totalité des prédictions (99,75%) a été assigné au cluster 0."
      ],
      "metadata": {
        "id": "1YygRvfbgtbf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###A.2 Normalisation des vecteurs représentant les documents"
      ],
      "metadata": {
        "id": "kLFACEoR6Xb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normalisation"
      ],
      "metadata": {
        "id": "l7qv303Dl96b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalisation\n",
        "from pyspark.ml.feature import Normalizer\n",
        "from pyspark.ml.linalg import Vectors\n",
        "normalizer = Normalizer(inputCol=\"features_hache\", outputCol=\"features\", p=1.0)\n",
        "l1NormData = normalizer.transform(featurizedData)\n",
        "l1NormData.show()"
      ],
      "metadata": {
        "id": "WDl5V4oRPm7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### KMeans avec normalisation"
      ],
      "metadata": {
        "id": "Fd4Ibmo-hNmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Kmeans avec normalisation\n",
        "K_means(l1NormData)"
      ],
      "metadata": {
        "id": "loOCJZS__EE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.B. Transformation de texte : En tete seulement\n",
        "\n",
        "Comme le résultat du clustering n'a pas donné des résultats satisfaisants, nous allons essayer les meme étapes sur l'entete des documents.\n",
        "\n",
        "Nous allons commencer par créer un nouvel RDD de type pyspark.sql.Row puis un dataframe qui a une seule colonne ne contenant que l'eentete. Ceci est pour faire un deuxieme test sur l'algorithme KMeans."
      ],
      "metadata": {
        "id": "RAaWnL0x6skN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ToRow_entete(x):\n",
        "  entete=x[1][0]\n",
        "  val=\" \".join(entete.values())\n",
        "  row = Row(entete=val)\n",
        "  return row\n",
        "\n",
        "entete_document_row=fusion.map(ToRow_entete)"
      ],
      "metadata": {
        "id": "x00n2EgYvmih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Entete_df=spark.createDataFrame(entete_document_row)\n",
        "Entete_df.printSchema()"
      ],
      "metadata": {
        "id": "oj4rLiASxluu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.B.2 Découpage les documents en listes de mots à l’aide de Tokenizer"
      ],
      "metadata": {
        "id": "Z8_vL6ZManSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer2 = Tokenizer(inputCol=\"entete\", outputCol=\"words\")\n",
        "#d=df.select(\"Contenu\")\n",
        "wordsData_entete = tokenizer2.transform(Entete_df)\n",
        "wordsData_entete.show()"
      ],
      "metadata": {
        "id": "W-uJzqmN6xb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5.B.3 Création d'une représentation vectorielle des documents à l’aide de HashingTF"
      ],
      "metadata": {
        "id": "mpAYldfPaw8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Création d'une représentation vectorielle des documents à l’aide de HashingTF\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"features_hache\", numFeatures=20)\n",
        "featurizedData_entete = hashingTF.transform(wordsData_entete)\n",
        "featurizedData_entete.show()"
      ],
      "metadata": {
        "id": "15Fo1jdb76YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6-7.B. Groupement des documents ayants des représentations vectorielles proches"
      ],
      "metadata": {
        "id": "X-fzLRBX-ANC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###B.1. KMeans avec ponderation Tf-Idf"
      ],
      "metadata": {
        "id": "oXrbH-zTjLQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pondération des mots avec la formule Tf-*Idf*"
      ],
      "metadata": {
        "id": "3FdT0LDai216"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idf = IDF(inputCol=\"features_hache\", outputCol=\"features\")\n",
        "idfModel = idf.fit(featurizedData)\n",
        "rescaledData_entete = idfModel.transform(featurizedData_entete)\n",
        "rescaledData_entete.show()"
      ],
      "metadata": {
        "id": "60Lb6dKk9pVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### KMeans avec ponderation Tf-Idf"
      ],
      "metadata": {
        "id": "QcofiQ5YjCqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K_means(rescaledData_entete)"
      ],
      "metadata": {
        "id": "_ppFIBsW9z3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###B.2. KMeans avec  normalisation"
      ],
      "metadata": {
        "id": "a5uMb9_g-dx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Normalisation"
      ],
      "metadata": {
        "id": "YSPI-C0Ejg7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalisation\n",
        "from pyspark.ml.feature import Normalizer\n",
        "from pyspark.ml.linalg import Vectors\n",
        "normalizer = Normalizer(inputCol=\"features_hache\", outputCol=\"features\", p=1.0)\n",
        "l1NormData_entete = normalizer.transform(featurizedData_entete)\n",
        "l1NormData_entete.show()"
      ],
      "metadata": {
        "id": "EbG54bua-hav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####KMeans avec normalisation"
      ],
      "metadata": {
        "id": "fBUrD6oVjknX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K_means(l1NormData_entete)"
      ],
      "metadata": {
        "id": "pZ9GboE6-5as"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}